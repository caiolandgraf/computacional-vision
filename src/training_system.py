#!/usr/bin/env python3
"""
Sistema de Treinamento AutomÃ¡tico para DetecÃ§Ã£o de VegetaÃ§Ã£o
Processa imagens e vÃ­deos das pastas de treinamento para melhorar o sistema de aprendizado adaptativo.
"""

import os
import cv2
import json
import logging
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Optional
from datetime import datetime
import glob

from detector import GrassDetector
from adaptive_learning import AdaptiveLearningSystem

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrainingSystem:
    def __init__(self, training_data_dir: str = "training_data"):
        """
        Inicializa o sistema de treinamento.
        
        Args:
            training_data_dir: DiretÃ³rio com os dados de treinamento
        """
        self.training_data_dir = Path(training_data_dir)
        self.detector = GrassDetector()
        self.learning_system = AdaptiveLearningSystem()
        
        # Criar estrutura de pastas se nÃ£o existir
        self._ensure_directories()
        
        # EstatÃ­sticas de treinamento
        self.training_stats = {
            'total_images_processed': 0,
            'vegetation_examples': 0,
            'non_vegetation_examples': 0,
            'ambiguous_examples': 0,
            'videos_processed': 0,
            'frames_extracted': 0,
            'training_sessions': 0,
            'last_training': None
        }
        
        # Carregar estatÃ­sticas existentes
        self._load_training_stats()
    
    def _ensure_directories(self):
        """Garante que todas as pastas necessÃ¡rias existem."""
        dirs_to_create = [
            self.training_data_dir,
            self.training_data_dir / "vegetation",
            self.training_data_dir / "non_vegetation", 
            self.training_data_dir / "ambiguous",
            self.training_data_dir / "videos",
            self.training_data_dir / "processed_frames",
            self.training_data_dir / "validation_results"
        ]
        
        for dir_path in dirs_to_create:
            dir_path.mkdir(exist_ok=True, parents=True)
            logger.info(f"ğŸ“ DiretÃ³rio garantido: {dir_path}")
    
    def _load_training_stats(self):
        """Carrega estatÃ­sticas de treinamento existentes."""
        stats_file = self.training_data_dir / "training_stats.json"
        if stats_file.exists():
            try:
                with open(stats_file, 'r', encoding='utf-8') as f:
                    self.training_stats.update(json.load(f))
                logger.info(f"ğŸ“Š EstatÃ­sticas carregadas: {stats_file}")
            except Exception as e:
                logger.warning(f"âŒ Erro ao carregar estatÃ­sticas: {e}")
    
    def _save_training_stats(self):
        """Salva estatÃ­sticas de treinamento."""
        stats_file = self.training_data_dir / "training_stats.json"
        try:
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.training_stats, f, indent=2, ensure_ascii=False)
            logger.info(f"ğŸ’¾ EstatÃ­sticas salvas: {stats_file}")
        except Exception as e:
            logger.error(f"âŒ Erro ao salvar estatÃ­sticas: {e}")
    
    def get_supported_image_formats(self) -> List[str]:
        """Retorna formatos de imagem suportados."""
        return ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.webp']
    
    def get_supported_video_formats(self) -> List[str]:
        """Retorna formatos de vÃ­deo suportados.""" 
        return ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.webm', '*.flv']
    
    def find_images_in_directory(self, directory: Path) -> List[Path]:
        """Encontra todas as imagens em um diretÃ³rio."""
        images = []
        for pattern in self.get_supported_image_formats():
            images.extend(directory.glob(pattern))
            images.extend(directory.glob(pattern.upper()))
        return sorted(images)
    
    def find_videos_in_directory(self, directory: Path) -> List[Path]:
        """Encontra todos os vÃ­deos em um diretÃ³rio.""" 
        videos = []
        for pattern in self.get_supported_video_formats():
            videos.extend(directory.glob(pattern))
            videos.extend(directory.glob(pattern.upper()))
        return sorted(videos)
    
    def extract_frames_from_video(self, video_path: Path, max_frames: int = 30) -> List[np.ndarray]:
        """
        Extrai frames de um vÃ­deo para treinamento.
        
        Args:
            video_path: Caminho para o vÃ­deo
            max_frames: NÃºmero mÃ¡ximo de frames a extrair
            
        Returns:
            Lista de frames como arrays numpy
        """
        frames = []
        
        try:
            cap = cv2.VideoCapture(str(video_path))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if total_frames == 0:
                logger.warning(f"âš ï¸ VÃ­deo vazio: {video_path}")
                return frames
            
            # Calcular intervalo para pegar frames distribuÃ­dos
            frame_interval = max(1, total_frames // max_frames)
            
            frame_count = 0
            extracted_count = 0
            
            while cap.isOpened() and extracted_count < max_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Extrair frame no intervalo calculado
                if frame_count % frame_interval == 0:
                    frames.append(frame.copy())
                    extracted_count += 1
                
                frame_count += 1
            
            cap.release()
            
            logger.info(f"ğŸ¬ ExtraÃ­dos {len(frames)} frames de {video_path}")
            self.training_stats['frames_extracted'] += len(frames)
            
        except Exception as e:
            logger.error(f"âŒ Erro ao extrair frames de {video_path}: {e}")
        
        return frames
    
    def save_extracted_frames(self, frames: List[np.ndarray], video_name: str, category: str = "unknown"):
        """
        Salva frames extraÃ­dos no disco.
        
        Args:
            frames: Lista de frames
            video_name: Nome base para os arquivos
            category: Categoria (vegetation, non_vegetation, ambiguous)
        """
        output_dir = self.training_data_dir / "processed_frames" / category
        output_dir.mkdir(exist_ok=True, parents=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for i, frame in enumerate(frames):
            filename = f"{video_name}_{timestamp}_frame_{i:03d}.jpg"
            output_path = output_dir / filename
            
            try:
                cv2.imwrite(str(output_path), frame)
                logger.info(f"ğŸ’¾ Frame salvo: {output_path}")
            except Exception as e:
                logger.error(f"âŒ Erro ao salvar frame {filename}: {e}")
    
    def process_training_image(self, image_path: Path, is_vegetation: bool) -> Dict:
        """
        Processa uma imagem de treinamento.
        
        Args:
            image_path: Caminho para a imagem
            is_vegetation: True se a imagem contÃ©m vegetaÃ§Ã£o
            
        Returns:
            Resultado do processamento
        """
        try:
            # Carregar imagem
            image = cv2.imread(str(image_path))
            if image is None:
                raise ValueError(f"NÃ£o foi possÃ­vel carregar a imagem: {image_path}")
            
            # Fazer detecÃ§Ã£o atual
            mask, result = self.detector.detect_grass_areas(image, method='combined')
            
            # Criar mÃ¡scara baseada na expectativa (para aprendizado)
            if is_vegetation:
                # Para exemplos de vegetaÃ§Ã£o, usar mÃ¡scara detectada como "correta"
                ground_truth_mask = mask
            else:
                # Para nÃ£o-vegetaÃ§Ã£o, criar mÃ¡scara vazia (sem vegetaÃ§Ã£o)
                ground_truth_mask = np.zeros_like(mask)
            
            # Treinar sistema adaptativo
            self.learning_system.learn_from_example(image, ground_truth_mask, is_vegetation)
            
            # Preparar resultado
            processing_result = {
                'image_path': str(image_path),
                'is_vegetation': is_vegetation,
                'detection_result': result,
                'processed_at': datetime.now().isoformat(),
                'image_size': image.shape[:2]
            }
            
            # Atualizar estatÃ­sticas
            self.training_stats['total_images_processed'] += 1
            if is_vegetation:
                self.training_stats['vegetation_examples'] += 1
            else:
                self.training_stats['non_vegetation_examples'] += 1
            
            logger.info(f"âœ… Processada: {image_path.name} (vegetaÃ§Ã£o: {is_vegetation})")
            
            return processing_result
            
        except Exception as e:
            logger.error(f"âŒ Erro ao processar {image_path}: {e}")
            return {
                'image_path': str(image_path),
                'error': str(e),
                'processed_at': datetime.now().isoformat()
            }
    
    def train_from_directory(self, directory_name: str, is_vegetation: bool) -> List[Dict]:
        """
        Treina com todas as imagens de um diretÃ³rio.
        
        Args:
            directory_name: Nome do diretÃ³rio (vegetation, non_vegetation, ambiguous)
            is_vegetation: Se as imagens contÃªm vegetaÃ§Ã£o
            
        Returns:
            Lista de resultados de processamento
        """
        directory_path = self.training_data_dir / directory_name
        
        if not directory_path.exists():
            logger.warning(f"âš ï¸ DiretÃ³rio nÃ£o encontrado: {directory_path}")
            return []
        
        # Encontrar todas as imagens
        images = self.find_images_in_directory(directory_path)
        
        if not images:
            logger.info(f"ğŸ“­ Nenhuma imagem encontrada em: {directory_path}")
            return []
        
        logger.info(f"ğŸ¯ Processando {len(images)} imagens de {directory_path}")
        
        results = []
        for image_path in images:
            result = self.process_training_image(image_path, is_vegetation)
            results.append(result)
        
        return results
    
    def process_videos(self) -> List[Dict]:
        """Processa todos os vÃ­deos na pasta de vÃ­deos."""
        videos_dir = self.training_data_dir / "videos"
        videos = self.find_videos_in_directory(videos_dir)
        
        if not videos:
            logger.info(f"ğŸ“­ Nenhum vÃ­deo encontrado em: {videos_dir}")
            return []
        
        logger.info(f"ğŸ¬ Processando {len(videos)} vÃ­deos")
        
        results = []
        for video_path in videos:
            try:
                # Extrair frames
                frames = self.extract_frames_from_video(video_path)
                
                if frames:
                    # Salvar frames extraÃ­dos
                    video_name = video_path.stem
                    self.save_extracted_frames(frames, video_name, "unknown")
                    
                    # Processar cada frame
                    for i, frame in enumerate(frames):
                        # Por enquanto, assumir que vÃ­deos podem ter vegetaÃ§Ã£o
                        # O usuÃ¡rio pode mover frames depois para categorias corretas
                        frame_result = {
                            'video_path': str(video_path),
                            'frame_index': i,
                            'extracted_at': datetime.now().isoformat(),
                            'frame_saved': True
                        }
                        results.append(frame_result)
                
                self.training_stats['videos_processed'] += 1
                logger.info(f"âœ… VÃ­deo processado: {video_path.name}")
                
            except Exception as e:
                logger.error(f"âŒ Erro ao processar vÃ­deo {video_path}: {e}")
                results.append({
                    'video_path': str(video_path),
                    'error': str(e),
                    'processed_at': datetime.now().isoformat()
                })
        
        return results
    
    def run_full_training(self) -> Dict:
        """
        Executa treinamento completo com todos os dados disponÃ­veis.
        
        Returns:
            RelatÃ³rio completo do treinamento
        """
        logger.info("ğŸš€ Iniciando treinamento completo...")
        
        training_report = {
            'started_at': datetime.now().isoformat(),
            'vegetation_results': [],
            'non_vegetation_results': [],
            'ambiguous_results': [], 
            'video_results': [],
            'errors': [],
            'summary': {}
        }
        
        try:
            # Processar imagens de vegetaÃ§Ã£o
            logger.info("ğŸŒ± Processando imagens de vegetaÃ§Ã£o...")
            training_report['vegetation_results'] = self.train_from_directory("vegetation", True)
            
            # Processar imagens de nÃ£o-vegetaÃ§Ã£o  
            logger.info("ğŸ¢ Processando imagens de nÃ£o-vegetaÃ§Ã£o...")
            training_report['non_vegetation_results'] = self.train_from_directory("non_vegetation", False)
            
            # Processar casos ambÃ­guos (assumir que podem ter vegetaÃ§Ã£o)
            logger.info("â“ Processando casos ambÃ­guos...")
            training_report['ambiguous_results'] = self.train_from_directory("ambiguous", True)
            self.training_stats['ambiguous_examples'] += len(training_report['ambiguous_results'])
            
            # Processar vÃ­deos
            logger.info("ğŸ¬ Processando vÃ­deos...")
            training_report['video_results'] = self.process_videos()
            
            # O sistema de aprendizado salva automaticamente
            logger.info("ğŸ’¾ Sistema de aprendizado salvo automaticamente!")
            
            # Atualizar estatÃ­sticas
            self.training_stats['training_sessions'] += 1
            self.training_stats['last_training'] = datetime.now().isoformat()
            self._save_training_stats()
            
            # Preparar sumÃ¡rio
            training_report['summary'] = {
                'total_images': len(training_report['vegetation_results']) + 
                              len(training_report['non_vegetation_results']) + 
                              len(training_report['ambiguous_results']),
                'total_videos': len([r for r in training_report['video_results'] if 'frame_index' not in r]),
                'total_frames': len([r for r in training_report['video_results'] if 'frame_index' in r]),
                'training_stats': self.training_stats.copy()
            }
            
            training_report['completed_at'] = datetime.now().isoformat()
            training_report['status'] = 'success'
            
            logger.info("âœ… Treinamento completo finalizado!")
            
        except Exception as e:
            logger.error(f"âŒ Erro durante treinamento: {e}")
            training_report['error'] = str(e)
            training_report['status'] = 'error'
            training_report['completed_at'] = datetime.now().isoformat()
        
        # Salvar relatÃ³rio
        self._save_training_report(training_report)
        
        return training_report
    
    def _save_training_report(self, report: Dict):
        """Salva relatÃ³rio de treinamento."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.training_data_dir / "validation_results" / f"training_report_{timestamp}.json"
        
        # FunÃ§Ã£o para serializar objetos nÃ£o-JSON
        def json_serializer(obj):
            if isinstance(obj, (np.bool_, bool)):
                return bool(obj)
            elif isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            return str(obj)
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=json_serializer)
            logger.info(f"ğŸ“„ RelatÃ³rio salvo: {report_file}")
        except Exception as e:
            logger.error(f"âŒ Erro ao salvar relatÃ³rio: {e}")
    
    def get_training_progress(self) -> Dict:
        """Retorna progresso atual do treinamento."""
        # Contar arquivos disponÃ­veis
        vegetation_count = len(self.find_images_in_directory(self.training_data_dir / "vegetation"))
        non_vegetation_count = len(self.find_images_in_directory(self.training_data_dir / "non_vegetation"))
        ambiguous_count = len(self.find_images_in_directory(self.training_data_dir / "ambiguous"))
        video_count = len(self.find_videos_in_directory(self.training_data_dir / "videos"))
        
        return {
            'available_data': {
                'vegetation_images': vegetation_count,
                'non_vegetation_images': non_vegetation_count,
                'ambiguous_images': ambiguous_count,
                'videos': video_count
            },
            'processing_stats': self.training_stats.copy(),
            'knowledge_base_size': self.learning_system.get_learning_stats(),
            'recommendations': self._generate_recommendations(vegetation_count, non_vegetation_count, video_count)
        }
    
    def _generate_recommendations(self, veg_count: int, non_veg_count: int, video_count: int) -> List[str]:
        """Gera recomendaÃ§Ãµes baseadas nos dados disponÃ­veis."""
        recommendations = []
        
        if veg_count == 0:
            recommendations.append("ğŸŒ± Adicione imagens de vegetaÃ§Ã£o na pasta 'training_data/vegetation'")
        
        if non_veg_count == 0:
            recommendations.append("ğŸ¢ Adicione imagens sem vegetaÃ§Ã£o na pasta 'training_data/non_vegetation'")
        
        if veg_count < 10:
            recommendations.append(f"ğŸ“¸ Adicione mais imagens de vegetaÃ§Ã£o (atual: {veg_count}, recomendado: 10+)")
        
        if non_veg_count < 10:
            recommendations.append(f"ğŸ“¸ Adicione mais imagens sem vegetaÃ§Ã£o (atual: {non_veg_count}, recomendado: 10+)")
        
        if video_count > 0:
            recommendations.append(f"ğŸ¬ {video_count} vÃ­deo(s) disponÃ­vel(eis) - execute o treinamento para extrair frames")
        
        if abs(veg_count - non_veg_count) > 20:
            recommendations.append("âš–ï¸ Balance melhor os dados - tenha quantidades similares de vegetaÃ§Ã£o e nÃ£o-vegetaÃ§Ã£o")
        
        if not recommendations:
            recommendations.append("âœ… Dados balanceados! Execute o treinamento para melhorar o sistema")
        
        return recommendations

def main():
    """FunÃ§Ã£o principal para execuÃ§Ã£o do sistema de treinamento."""
    print("ğŸ“ Sistema de Treinamento de VegetaÃ§Ã£o")
    print("=" * 50)
    
    # Inicializar sistema
    training_system = TrainingSystem()
    
    # Mostrar progresso atual
    progress = training_system.get_training_progress()
    
    print("\nğŸ“Š Estado Atual dos Dados:")
    print(f"  ğŸŒ± Imagens de vegetaÃ§Ã£o: {progress['available_data']['vegetation_images']}")
    print(f"  ğŸ¢ Imagens sem vegetaÃ§Ã£o: {progress['available_data']['non_vegetation_images']}")  
    print(f"  â“ Casos ambÃ­guos: {progress['available_data']['ambiguous_images']}")
    print(f"  ğŸ¬ VÃ­deos: {progress['available_data']['videos']}")
    
    print(f"\nğŸ“ˆ EstatÃ­sticas de Processamento:")
    stats = progress['processing_stats']
    print(f"  ğŸ“¸ Total processado: {stats['total_images_processed']} imagens")
    print(f"  ğŸ¬ VÃ­deos processados: {stats['videos_processed']}")
    print(f"  ğŸ­ Frames extraÃ­dos: {stats['frames_extracted']}")
    print(f"  ğŸ¯ SessÃµes de treinamento: {stats['training_sessions']}")
    
    if stats['last_training']:
        print(f"  â° Ãšltimo treinamento: {stats['last_training']}")
    
    print(f"\nğŸ’¡ RecomendaÃ§Ãµes:")
    for rec in progress['recommendations']:
        print(f"  {rec}")
    
    # Perguntar se quer executar treinamento
    if progress['available_data']['vegetation_images'] > 0 or progress['available_data']['non_vegetation_images'] > 0 or progress['available_data']['videos'] > 0:
        print(f"\nâ“ Executar treinamento com dados disponÃ­veis? (s/n): ", end="")
        response = input().lower().strip()
        
        if response in ['s', 'sim', 'y', 'yes']:
            print("\nğŸš€ Iniciando treinamento...")
            report = training_system.run_full_training()
            
            if report['status'] == 'success':
                summary = report['summary']
                print(f"\nâœ… Treinamento concluÃ­do com sucesso!")
                print(f"  ğŸ“¸ Imagens processadas: {summary['total_images']}")
                print(f"  ğŸ¬ VÃ­deos processados: {summary['total_videos']}")
                print(f"  ğŸ­ Frames extraÃ­dos: {summary['total_frames']}")
                print(f"\nğŸ§  Sistema de aprendizado atualizado e salvo!")
            else:
                print(f"\nâŒ Erro durante treinamento: {report.get('error', 'Erro desconhecido')}")
        else:
            print("\nğŸ“‹ Treinamento cancelado. Adicione mais dados e execute novamente.")
    else:
        print(f"\nğŸ“­ Nenhum dado de treinamento encontrado.")
        print(f"   Adicione imagens nas pastas:")
        print(f"   - training_data/vegetation/ (imagens com vegetaÃ§Ã£o)")
        print(f"   - training_data/non_vegetation/ (imagens sem vegetaÃ§Ã£o)")
        print(f"   - training_data/videos/ (vÃ­deos para extrair frames)")

if __name__ == "__main__":
    main()
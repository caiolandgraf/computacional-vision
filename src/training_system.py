#!/usr/bin/env python3
"""
Sistema de Treinamento Autom√°tico para Detec√ß√£o de Vegeta√ß√£o
Processa imagens e v√≠deos das pastas de treinamento para melhorar o sistema de aprendizado adaptativo.
"""

import os
import cv2
import json
import logging
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Optional
from datetime import datetime
import glob

from detector import GrassDetector
from adaptive_learning import AdaptiveLearningSystem

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrainingSystem:
    def __init__(self, training_data_dir: str = "training_data"):
        """
        Inicializa o sistema de treinamento.
        
        Args:
            training_data_dir: Diret√≥rio com os dados de treinamento
        """
        self.training_data_dir = Path(training_data_dir)
        self.detector = GrassDetector()
        self.learning_system = AdaptiveLearningSystem()
        
        # Criar estrutura de pastas se n√£o existir
        self._ensure_directories()
        
        # Estat√≠sticas de treinamento
        self.training_stats = {
            'total_images_processed': 0,
            'vegetation_examples': 0,
            'non_vegetation_examples': 0,
            'ambiguous_examples': 0,
            'videos_processed': 0,
            'frames_extracted': 0,
            'training_sessions': 0,
            'last_training': None
        }
        
        # Carregar estat√≠sticas existentes
        self._load_training_stats()
    
    def _ensure_directories(self):
        """Garante que todas as pastas necess√°rias existem."""
        dirs_to_create = [
            self.training_data_dir,
            self.training_data_dir / "vegetation",
            self.training_data_dir / "non_vegetation", 
            self.training_data_dir / "ambiguous",
            self.training_data_dir / "videos",
            self.training_data_dir / "processed_frames",
            self.training_data_dir / "validation_results"
        ]
        
        for dir_path in dirs_to_create:
            dir_path.mkdir(exist_ok=True, parents=True)
            logger.info(f"üìÅ Diret√≥rio garantido: {dir_path}")
    
    def _load_training_stats(self):
        """Carrega estat√≠sticas de treinamento existentes."""
        stats_file = self.training_data_dir / "training_stats.json"
        if stats_file.exists():
            try:
                with open(stats_file, 'r', encoding='utf-8') as f:
                    self.training_stats.update(json.load(f))
                logger.info(f"üìä Estat√≠sticas carregadas: {stats_file}")
            except Exception as e:
                logger.warning(f"‚ùå Erro ao carregar estat√≠sticas: {e}")
    
    def _save_training_stats(self):
        """Salva estat√≠sticas de treinamento."""
        stats_file = self.training_data_dir / "training_stats.json"
        try:
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.training_stats, f, indent=2, ensure_ascii=False)
            logger.info(f"üíæ Estat√≠sticas salvas: {stats_file}")
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar estat√≠sticas: {e}")
    
    def get_supported_image_formats(self) -> List[str]:
        """Retorna formatos de imagem suportados."""
        return ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.webp']
    
    def get_supported_video_formats(self) -> List[str]:
        """Retorna formatos de v√≠deo suportados.""" 
        return ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.webm', '*.flv']
    
    def find_images_in_directory(self, directory: Path) -> List[Path]:
        """Encontra todas as imagens em um diret√≥rio."""
        images = []
        for pattern in self.get_supported_image_formats():
            images.extend(directory.glob(pattern))
            images.extend(directory.glob(pattern.upper()))
        return sorted(images)
    
    def find_videos_in_directory(self, directory: Path) -> List[Path]:
        """Encontra todos os v√≠deos em um diret√≥rio.""" 
        videos = []
        for pattern in self.get_supported_video_formats():
            videos.extend(directory.glob(pattern))
            videos.extend(directory.glob(pattern.upper()))
        return sorted(videos)
    
    def extract_frames_from_video(self, video_path: Path, max_frames: int = 30) -> List[np.ndarray]:
        """
        Extrai frames de um v√≠deo para treinamento.
        
        Args:
            video_path: Caminho para o v√≠deo
            max_frames: N√∫mero m√°ximo de frames a extrair
            
        Returns:
            Lista de frames como arrays numpy
        """
        frames = []
        
        try:
            cap = cv2.VideoCapture(str(video_path))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if total_frames == 0:
                logger.warning(f"‚ö†Ô∏è V√≠deo vazio: {video_path}")
                return frames
            
            # Calcular intervalo para pegar frames distribu√≠dos
            frame_interval = max(1, total_frames // max_frames)
            
            frame_count = 0
            extracted_count = 0
            
            while cap.isOpened() and extracted_count < max_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Extrair frame no intervalo calculado
                if frame_count % frame_interval == 0:
                    frames.append(frame.copy())
                    extracted_count += 1
                
                frame_count += 1
            
            cap.release()
            
            logger.info(f"üé¨ Extra√≠dos {len(frames)} frames de {video_path}")
            self.training_stats['frames_extracted'] += len(frames)
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair frames de {video_path}: {e}")
        
        return frames
    
    def save_extracted_frames(self, frames: List[np.ndarray], video_name: str, category: str = "unknown"):
        """
        Salva frames extra√≠dos no disco.
        
        Args:
            frames: Lista de frames
            video_name: Nome base para os arquivos
            category: Categoria (vegetation, non_vegetation, ambiguous)
        """
        output_dir = self.training_data_dir / "processed_frames" / category
        output_dir.mkdir(exist_ok=True, parents=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for i, frame in enumerate(frames):
            filename = f"{video_name}_{timestamp}_frame_{i:03d}.jpg"
            output_path = output_dir / filename
            
            try:
                cv2.imwrite(str(output_path), frame)
                logger.info(f"üíæ Frame salvo: {output_path}")
            except Exception as e:
                logger.error(f"‚ùå Erro ao salvar frame {filename}: {e}")
    
    def process_training_image(self, image_path: Path, is_vegetation: bool) -> Dict:
        """
        Processa uma imagem de treinamento.
        
        Args:
            image_path: Caminho para a imagem
            is_vegetation: True se a imagem cont√©m vegeta√ß√£o
            
        Returns:
            Resultado do processamento
        """
        try:
            # Carregar imagem
            image = cv2.imread(str(image_path))
            if image is None:
                raise ValueError(f"N√£o foi poss√≠vel carregar a imagem: {image_path}")
            
            # Fazer detec√ß√£o atual
            mask, result = self.detector.detect_grass_areas(image, method='combined')
            
            # Criar m√°scara baseada na expectativa (para aprendizado)
            if is_vegetation:
                # Para exemplos de vegeta√ß√£o, usar m√°scara detectada como "correta"
                ground_truth_mask = mask
            else:
                # Para n√£o-vegeta√ß√£o, criar m√°scara vazia (sem vegeta√ß√£o)
                ground_truth_mask = np.zeros_like(mask)
            
            # Treinar sistema adaptativo
            self.learning_system.learn_from_example(image, ground_truth_mask, is_vegetation)
            
            # Preparar resultado
            processing_result = {
                'image_path': str(image_path),
                'is_vegetation': is_vegetation,
                'detection_result': result,
                'processed_at': datetime.now().isoformat(),
                'image_size': image.shape[:2]
            }
            
            # Atualizar estat√≠sticas
            self.training_stats['total_images_processed'] += 1
            if is_vegetation:
                self.training_stats['vegetation_examples'] += 1
            else:
                self.training_stats['non_vegetation_examples'] += 1
            
            logger.info(f"‚úÖ Processada: {image_path.name} (vegeta√ß√£o: {is_vegetation})")
            
            return processing_result
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar {image_path}: {e}")
            return {
                'image_path': str(image_path),
                'error': str(e),
                'processed_at': datetime.now().isoformat()
            }
    
    def train_from_directory(self, directory_name: str, is_vegetation: bool) -> List[Dict]:
        """
        Treina com todas as imagens de um diret√≥rio.
        
        Args:
            directory_name: Nome do diret√≥rio (vegetation, non_vegetation, ambiguous)
            is_vegetation: Se as imagens cont√™m vegeta√ß√£o
            
        Returns:
            Lista de resultados de processamento
        """
        directory_path = self.training_data_dir / directory_name
        
        if not directory_path.exists():
            logger.warning(f"‚ö†Ô∏è Diret√≥rio n√£o encontrado: {directory_path}")
            return []
        
        # Encontrar todas as imagens
        images = self.find_images_in_directory(directory_path)
        
        if not images:
            logger.info(f"üì≠ Nenhuma imagem encontrada em: {directory_path}")
            return []
        
        logger.info(f"üéØ Processando {len(images)} imagens de {directory_path}")
        
        results = []
        for image_path in images:
            result = self.process_training_image(image_path, is_vegetation)
            results.append(result)
        
        return results
    
    def process_videos(self) -> List[Dict]:
        """Processa todos os v√≠deos na pasta de v√≠deos."""
        videos_dir = self.training_data_dir / "videos"
        videos = self.find_videos_in_directory(videos_dir)
        
        if not videos:
            logger.info(f"üì≠ Nenhum v√≠deo encontrado em: {videos_dir}")
            return []
        
        logger.info(f"üé¨ Processando {len(videos)} v√≠deos")
        
        results = []
        for video_path in videos:
            try:
                # Extrair frames
                frames = self.extract_frames_from_video(video_path)
                
                if frames:
                    # Salvar frames extra√≠dos
                    video_name = video_path.stem
                    self.save_extracted_frames(frames, video_name, "unknown")
                    
                    # Processar cada frame
                    for i, frame in enumerate(frames):
                        # Por enquanto, assumir que v√≠deos podem ter vegeta√ß√£o
                        # O usu√°rio pode mover frames depois para categorias corretas
                        frame_result = {
                            'video_path': str(video_path),
                            'frame_index': i,
                            'extracted_at': datetime.now().isoformat(),
                            'frame_saved': True
                        }
                        results.append(frame_result)
                
                self.training_stats['videos_processed'] += 1
                logger.info(f"‚úÖ V√≠deo processado: {video_path.name}")
                
            except Exception as e:
                logger.error(f"‚ùå Erro ao processar v√≠deo {video_path}: {e}")
                results.append({
                    'video_path': str(video_path),
                    'error': str(e),
                    'processed_at': datetime.now().isoformat()
                })
        
        return results
    
    def run_full_training(self) -> Dict:
        """
        Executa treinamento completo com todos os dados dispon√≠veis.
        
        Returns:
            Relat√≥rio completo do treinamento
        """
        logger.info("üöÄ Iniciando treinamento completo...")
        
        training_report = {
            'started_at': datetime.now().isoformat(),
            'vegetation_results': [],
            'non_vegetation_results': [],
            'ambiguous_results': [], 
            'video_results': [],
            'errors': [],
            'summary': {}
        }
        
        try:
            # Processar imagens de vegeta√ß√£o
            logger.info("üå± Processando imagens de vegeta√ß√£o...")
            training_report['vegetation_results'] = self.train_from_directory("vegetation", True)
            
            # Processar imagens de n√£o-vegeta√ß√£o  
            logger.info("üè¢ Processando imagens de n√£o-vegeta√ß√£o...")
            training_report['non_vegetation_results'] = self.train_from_directory("non_vegetation", False)
            
            # Processar casos amb√≠guos (assumir que podem ter vegeta√ß√£o)
            logger.info("‚ùì Processando casos amb√≠guos...")
            training_report['ambiguous_results'] = self.train_from_directory("ambiguous", True)
            self.training_stats['ambiguous_examples'] += len(training_report['ambiguous_results'])
            
            # Processar v√≠deos
            logger.info("üé¨ Processando v√≠deos...")
            training_report['video_results'] = self.process_videos()
            
            # O sistema de aprendizado salva automaticamente
            logger.info("üíæ Sistema de aprendizado salvo automaticamente!")
            
            # Atualizar estat√≠sticas
            self.training_stats['training_sessions'] += 1
            self.training_stats['last_training'] = datetime.now().isoformat()
            self._save_training_stats()
            
            # Preparar sum√°rio
            training_report['summary'] = {
                'total_images': len(training_report['vegetation_results']) + 
                              len(training_report['non_vegetation_results']) + 
                              len(training_report['ambiguous_results']),
                'total_videos': len([r for r in training_report['video_results'] if 'frame_index' not in r]),
                'total_frames': len([r for r in training_report['video_results'] if 'frame_index' in r]),
                'training_stats': self.training_stats.copy()
            }
            
            training_report['completed_at'] = datetime.now().isoformat()
            training_report['status'] = 'success'
            
            logger.info("‚úÖ Treinamento completo finalizado!")
            
        except Exception as e:
            logger.error(f"‚ùå Erro durante treinamento: {e}")
            training_report['error'] = str(e)
            training_report['status'] = 'error'
            training_report['completed_at'] = datetime.now().isoformat()
        
        # Salvar relat√≥rio
        self._save_training_report(training_report)
        
        return training_report
    
    def _save_training_report(self, report: Dict):
        """Salva relat√≥rio de treinamento."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.training_data_dir / "validation_results" / f"training_report_{timestamp}.json"
        
        # Fun√ß√£o para serializar objetos n√£o-JSON
        def json_serializer(obj):
            if isinstance(obj, (np.bool_, bool)):
                return bool(obj)
            elif isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            return str(obj)
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=json_serializer)
            logger.info(f"üìÑ Relat√≥rio salvo: {report_file}")
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar relat√≥rio: {e}")
    
    def get_training_progress(self) -> Dict:
        """Retorna progresso atual do treinamento."""
        # Contar arquivos dispon√≠veis
        vegetation_count = len(self.find_images_in_directory(self.training_data_dir / "vegetation"))
        non_vegetation_count = len(self.find_images_in_directory(self.training_data_dir / "non_vegetation"))
        ambiguous_count = len(self.find_images_in_directory(self.training_data_dir / "ambiguous"))
        video_count = len(self.find_videos_in_directory(self.training_data_dir / "videos"))
        
        return {
            'available_data': {
                'vegetation_images': vegetation_count,
                'non_vegetation_images': non_vegetation_count,
                'ambiguous_images': ambiguous_count,
                'videos': video_count
            },
            'processing_stats': self.training_stats.copy(),
            'knowledge_base_size': self.learning_system.get_learning_stats(),
            'recommendations': self._generate_recommendations(vegetation_count, non_vegetation_count, video_count)
        }
    
    def _generate_recommendations(self, veg_count: int, non_veg_count: int, video_count: int) -> List[str]:
        """Gera recomenda√ß√µes baseadas nos dados dispon√≠veis."""
        recommendations = []
        
        if veg_count == 0:
            recommendations.append("üå± Adicione imagens de vegeta√ß√£o na pasta 'training_data/vegetation'")
        
        if non_veg_count == 0:
            recommendations.append("üè¢ Adicione imagens sem vegeta√ß√£o na pasta 'training_data/non_vegetation'")
        
        if veg_count < 10:
            recommendations.append(f"üì∏ Adicione mais imagens de vegeta√ß√£o (atual: {veg_count}, recomendado: 10+)")
        
        if non_veg_count < 10:
            recommendations.append(f"üì∏ Adicione mais imagens sem vegeta√ß√£o (atual: {non_veg_count}, recomendado: 10+)")
        
        if video_count > 0:
            recommendations.append(f"üé¨ {video_count} v√≠deo(s) dispon√≠vel(eis) - execute o treinamento para extrair frames")
        
        if abs(veg_count - non_veg_count) > 20:
            recommendations.append("‚öñÔ∏è Balance melhor os dados - tenha quantidades similares de vegeta√ß√£o e n√£o-vegeta√ß√£o")
        
        if not recommendations:
            recommendations.append("‚úÖ Dados balanceados! Execute o treinamento para melhorar o sistema")
        
        return recommendations

def main():
    """Fun√ß√£o principal para execu√ß√£o do sistema de treinamento."""
    print("üéì Sistema de Treinamento de Vegeta√ß√£o")
    print("=" * 50)
    
    # Inicializar sistema
    training_system = TrainingSystem()
    
    # Mostrar progresso atual
    progress = training_system.get_training_progress()
    
    print("\nüìä Estado Atual dos Dados:")
    print(f"  üå± Imagens de vegeta√ß√£o: {progress['available_data']['vegetation_images']}")
    print(f"  üè¢ Imagens sem vegeta√ß√£o: {progress['available_data']['non_vegetation_images']}")  
    print(f"  ‚ùì Casos amb√≠guos: {progress['available_data']['ambiguous_images']}")
    print(f"  üé¨ V√≠deos: {progress['available_data']['videos']}")
    
    print(f"\nüìà Estat√≠sticas de Processamento:")
    stats = progress['processing_stats']
    print(f"  üì∏ Total processado: {stats['total_images_processed']} imagens")
    print(f"  üé¨ V√≠deos processados: {stats['videos_processed']}")
    print(f"  üé≠ Frames extra√≠dos: {stats['frames_extracted']}")
    print(f"  üéØ Sess√µes de treinamento: {stats['training_sessions']}")
    
    if stats['last_training']:
        print(f"  ‚è∞ √öltimo treinamento: {stats['last_training']}")
    
    print(f"\nüí° Recomenda√ß√µes:")
    for rec in progress['recommendations']:
        print(f"  {rec}")
    
    # Perguntar se quer executar treinamento
    if progress['available_data']['vegetation_images'] > 0 or progress['available_data']['non_vegetation_images'] > 0 or progress['available_data']['videos'] > 0:
        print(f"\n‚ùì Executar treinamento com dados dispon√≠veis? (s/n): ", end="")
        response = input().lower().strip()
        
        if response in ['s', 'sim', 'y', 'yes']:
            print("\nüöÄ Iniciando treinamento...")
            report = training_system.run_full_training()
            
            if report['status'] == 'success':
                summary = report['summary']
                print(f"\n‚úÖ Treinamento conclu√≠do com sucesso!")
                print(f"  üì∏ Imagens processadas: {summary['total_images']}")
                print(f"  üé¨ V√≠deos processados: {summary['total_videos']}")
                print(f"  üé≠ Frames extra√≠dos: {summary['total_frames']}")
                print(f"\nüß† Sistema de aprendizado atualizado e salvo!")
            else:
                print(f"\n‚ùå Erro durante treinamento: {report.get('error', 'Erro desconhecido')}")
        else:
            print("\nüìã Treinamento cancelado. Adicione mais dados e execute novamente.")
    else:
        print(f"\nüì≠ Nenhum dado de treinamento encontrado.")
        print(f"   Adicione imagens nas pastas:")
        print(f"   - training_data/vegetation/ (imagens com vegeta√ß√£o)")
        print(f"   - training_data/non_vegetation/ (imagens sem vegeta√ß√£o)")
        print(f"   - training_data/videos/ (v√≠deos para extrair frames)")

if __name__ == "__main__":
    main()